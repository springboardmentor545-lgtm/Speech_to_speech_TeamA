# ğŸ¤ Speech-to-Speech Translation Pipeline

A real-time Speech-to-Speech translation system built with Azure Cognitive Services. This project implements a complete pipeline that captures speech, transcribes it, translates it to multiple languages, and generates speech output.

## ğŸ“‹ Project Overview

This project is divided into three milestones:

- **Milestone 1**: Speech-to-Text (STT) - âœ… Completed
- **Milestone 2**: Translation Module - âœ… Completed  
- **Milestone 3**: Full Real-Time Speech-to-Speech Pipeline - âœ… Completed

## ğŸ—ï¸ Architecture

```
Microphone Input
    â†“
[Azure Speech-to-Text] â†’ Transcript (with IDs)
    â†“
[Azure Translator] â†’ Translations (multiple languages)
    â†“
[Azure Text-to-Speech] â†’ Audio Output (per language)
```

## ğŸš€ Features

- **Real-time Speech Recognition**: Continuous microphone input with partial and final results
- **Multi-language Translation**: Translate to Hindi, Telugu, Spanish, French (configurable)
- **Text-to-Speech**: Generate natural-sounding audio in target languages
- **Transcript Management**: Track transcripts with unique IDs
- **Error Handling**: Retry logic for API failures
- **Performance Metrics**: Track STT, translation, and TTS latencies

## ğŸ“¦ Prerequisites

- Python 3.8+
- Azure account with the following services:
  - **Azure Speech Service** (for STT and TTS)
  - **Azure Translator Service**
- Microphone access

## ğŸ”§ Installation

1. **Clone the repository**:
   ```bash
   git clone <your-repo-url>
   cd somu-chandu
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**:
   Create a `.env` file in the root directory:
   ```env
   AZURE_SPEECH_KEY=your_speech_key_here
   AZURE_REGION=your_region_here
   AZURE_TRANSLATOR_KEY=your_translator_key_here
   AZURE_TRANSLATOR_REGION=your_region_here
   ```

   > **Note**: You can use the same region for both services, or specify `AZURE_TRANSLATOR_REGION` separately.

## ğŸ“ Project Structure

```
somu-chandu/
â”œâ”€â”€ app.py                            # Streamlit web interface
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ transcribe_files.py          # Milestone 1: File transcription
â”‚   â”œâ”€â”€ recognize_once.py            # Milestone 1: Real-time STT
â”‚   â”œâ”€â”€ auto_convert_transcribe.py   # Milestone 1: Auto-convert + transcribe
â”‚   â”œâ”€â”€ translator.py                # Milestone 2: Translation module
â”‚   â”œâ”€â”€ stt_translate_integration.py # Milestone 2: STT + Translation
â”‚   â”œâ”€â”€ realtime_speech_to_speech.py # Milestone 3: Full pipeline
â”‚   â””â”€â”€ test_pipeline.py             # Component testing script
â”œâ”€â”€ speech_samples/                   # Input audio files
â”œâ”€â”€ transcripts/                      # STT output
â”œâ”€â”€ translations/                     # Translation output
â”œâ”€â”€ realtime_output/                  # Milestone 3 output
â”‚   â”œâ”€â”€ audio/                        # TTS audio files
â”‚   â”œâ”€â”€ transcripts/                  # Real-time transcripts
â”‚   â””â”€â”€ translations/                 # Real-time translations
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ QUICKSTART.md
```

## ğŸ¯ Usage

### ğŸŒ Web Interface (Streamlit)

**Launch the web interface:**
```bash
streamlit run app.py
```

The web interface provides:
- ğŸ  **Home**: Overview and quick start guide
- ğŸ¤ **Real-Time Pipeline**: Instructions for running the live pipeline
- ğŸ“ **File Upload**: Upload and process audio files with transcription and translation
- ğŸ“Š **Results**: View and download generated audio files
- ğŸ§ª **Test Components**: Test individual components (STT, Translation, TTS)

**Features:**
- User-friendly interface
- Real-time processing feedback
- Audio playback in browser
- Download generated audio files
- Component testing tools

### Milestone 1: Speech-to-Text

#### Transcribe audio files:
```bash
python scripts/transcribe_files.py
```

#### Real-time microphone transcription:
```bash
python scripts/recognize_once.py
```
Say "end recording" to stop, or press Ctrl+C.

#### Auto-convert and transcribe:
```bash
python scripts/auto_convert_transcribe.py
```

### Milestone 2: Translation

#### Test translation module:
```bash
python scripts/translator.py
```

#### Translate transcripts from CSV:
```bash
python scripts/stt_translate_integration.py
```

### Milestone 3: Real-Time Speech-to-Speech

#### Run the full pipeline:
```bash
python scripts/realtime_speech_to_speech.py
```

**How it works:**
1. Start speaking into your microphone
2. The system will:
   - Transcribe your speech in real-time
   - Translate to target languages (hi, te, es, fr)
   - Generate audio output for each translation
3. Press **Ctrl+C** to stop

**Output:**
- Transcripts saved to `realtime_output/transcripts/`
- Translations saved to `realtime_output/translations/`
- Audio files saved to `realtime_output/audio/`

## âš™ï¸ Configuration

### Target Languages

Edit `scripts/realtime_speech_to_speech.py` to change target languages:

```python
TARGET_LANGUAGES = ["hi", "te", "es", "fr"]  # Add/remove languages
```

### Source Language

Change the source language for STT:

```python
SOURCE_LANGUAGE = "en-US"  # Change to your source language
```

### TTS Voices

The system uses neural voices for each language:
- Hindi: `hi-IN-SwaraNeural`
- Telugu: `te-IN-MohanNeural`
- Spanish: `es-ES-ElviraNeural`
- French: `fr-FR-DeniseNeural`

You can modify voice mappings in `_generate_tts()` method.

## ğŸ“Š Output Format

### Transcripts CSV
```csv
filename,language,language_name,transcript
en_commentary1.wav,en-US,English,"Communication technology has evolved..."
```

### Translations JSON
```json
{
  "transcript_id": "transcript_0_1234567890",
  "original_text": "Hello, how are you?",
  "translations": {
    "hi": "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?",
    "te": "à°¨à°®à°¸à±à°•à°¾à°°à°‚, à°®à±€à°°à± à°à°²à°¾ à°‰à°¨à±à°¨à°¾à°°à±?",
    "es": "Hola, Â¿cÃ³mo estÃ¡s?",
    "fr": "Bonjour, comment allez-vous?"
  },
  "source_language": "en",
  "timestamp": "2024-01-15 10:30:45",
  "translation_time": 0.85
}
```

## ğŸ” Troubleshooting

### "Missing Azure credentials"
- Ensure your `.env` file exists and contains all required keys
- Check that variable names match exactly (case-sensitive)

### "No speech recognized"
- Check microphone permissions
- Ensure microphone is working
- Try speaking louder or closer to the microphone

### Translation failures
- Verify Azure Translator service is active
- Check API key and region are correct
- Ensure you have sufficient quota

### TTS audio not generated
- Verify Azure Speech service includes TTS (usually included)
- Check voice names are valid for your region
- Review error messages in console output

## ğŸ“ˆ Performance Metrics

The pipeline tracks:
- **STT Latency**: Time to recognize speech
- **Translation Latency**: Time to translate text
- **TTS Latency**: Time to generate audio

These are displayed in the summary at the end of each session.

## ğŸ› ï¸ Development

### Adding New Languages

1. Add language code to `TARGET_LANGUAGES`
2. Add voice mapping in `_generate_tts()`:
   ```python
   voice_map = {
       "new_lang": "new-lang-Locale-VoiceNeural"
   }
   ```

### Extending Functionality

- **VAD (Voice Activity Detection)**: Can be added using Azure Speech SDK's silence detection
- **Streaming TTS**: Can be enhanced to stream audio directly to speakers
- **Web Interface**: Can be wrapped in Flask/FastAPI for web access

## ğŸ“ Sample Input/Output

### Input (Speech)
> "Hello, how are you today? I hope you're doing well."

### Output (Translations)
- **Hindi**: "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤œ à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚? à¤®à¥à¤à¥‡ à¤†à¤¶à¤¾ à¤¹à¥ˆ à¤•à¤¿ à¤†à¤ª à¤…à¤šà¥à¤›à¤¾ à¤•à¤° à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚à¥¤"
- **Telugu**: "à°¨à°®à°¸à±à°•à°¾à°°à°‚, à°®à±€à°°à± à°ˆà°°à±‹à°œà± à°à°²à°¾ à°‰à°¨à±à°¨à°¾à°°à±? à°®à±€à°°à± à°¬à°¾à°—à°¾ à°šà±‡à°¸à±à°¤à±à°¨à±à°¨à°¾à°°à°¨à°¿ à°¨à±‡à°¨à± à°†à°¶à°¿à°¸à±à°¤à±à°¨à±à°¨à°¾à°¨à±."
- **Spanish**: "Hola, Â¿cÃ³mo estÃ¡s hoy? Espero que lo estÃ©s haciendo bien."
- **French**: "Bonjour, comment allez-vous aujourd'hui ? J'espÃ¨re que vous allez bien."

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is for educational purposes.

## ğŸ™ Acknowledgments

- Azure Cognitive Services for Speech and Translation APIs
- Python community for excellent libraries

## ğŸ“ Support

For issues or questions:
1. Check the troubleshooting section
2. Review Azure service documentation
3. Open an issue on GitHub

---

**Built with â¤ï¸ using Azure Cognitive Services**

